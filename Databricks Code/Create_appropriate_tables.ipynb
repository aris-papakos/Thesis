{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Physics arxiv's DOI retreived - 603.178 DOIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"------------------------------\" #Path has removed for confidentiality reasons\n",
    "physics_doi= sqlContext.read.format('csv').options(header='true', inferSchema='true').option(\"delimiter\", \",\").load(path)\n",
    "physics_doi.write.mode(\"overwrite\").saveAsTable(\"taxiarchis.physics_doi_csv\")\n",
    "display(physics_doi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine DOIs with the scopus papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%scala\n",
    "//DONT EXECUTE , ONLY IF YOU WANT TO TAKE A SUBSET\n",
    "// val number_of_articles = 10000  //Select the number of articles to be retreived out of 64.500 DOIs\n",
    "\n",
    "val arxiv = table(\"taxiarchis.physics_doi_csv\").withColumnRenamed(\"DOI\", \"DOI_arxiv\")\n",
    "\n",
    "\n",
    "val sd_old = table(\"-----------\") // #Mapping table name has removed for confidentiality reasons\n",
    "val joined = arxiv.join(sd_old, sd_old(\"doi\") === arxiv(\"DOI_arxiv\"), \"inner\")\n",
    "\n",
    "val xmls   = \"----------------------------\" #Path has removed for confidentiality reasons\n",
    "val sd = sc.sequenceFile[String, String](xmls)\n",
    "\n",
    "case class SDmeta  (\n",
    "                     pii_unformatted: String, \n",
    "                     content: String\n",
    ")\n",
    "\n",
    "import org.apache.spark.sql.functions._\n",
    "import scala.collection.JavaConverters._\n",
    "\n",
    "// Map the transformed records to the CAR record  and create a CAR dataset\n",
    "var metaDS = sd.map(rec => new SDmeta(  rec._1, rec._2 )).toDF\n",
    "\n",
    "val final_joined = joined.join(metaDS, joined(\"pii_unformatted\") === metaDS(\"pii_unformatted\"), \"inner\").select(\"DOI_arxiv\", \"content\", \"Categories\")\n",
    "\n",
    "\n",
    "def generateHTMLLinks(pathInsideFileStore: String): String = {\n",
    "  /* path should be inside FileStore, but can remove the dbfs:/FileStore from the path if needed */\n",
    "  val pathInsideFileStore_clean=pathInsideFileStore.replace(\"-------------\",\"\")#Path has removed for confidentiality reasons\n",
    "  dbutils\n",
    "  .fs\n",
    "  .ls(s\"----------------------------------\") #Path has removed for confidentiality reasons\n",
    "  .map(_.name)\n",
    "  .map(\n",
    "    item => s\"\"\"-------------------------------------\"\"\" #Path has removed for confidentiality reasons\n",
    "  ).mkString(\n",
    "    \"\"\n",
    "  )\n",
    "}\n",
    "\n",
    "display(final_joined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select the categories you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%scala\n",
    "val test =final_joined.filter((final_joined(\"Categories\") === \"Condensed Matter - Statistical Mechanics\") || (final_joined(\"Categories\")  === \"Condensed Matter - Mesoscale and Nanoscale Physics\") || (final_joined(\"Categories\") === \"Condensed Matter - Materials Science\" ) || (final_joined(\"Categories\") === \"Condensed Matter - Strongly Correlated Electrons\" ))\n",
    "test.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Download as .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%scala\n",
    "\n",
    "test.repartition(1).write.mode(\"overwrite\").format(\"com.databricks.spark.csv\").option(\"header\", \"true\").option(\"delimiter\", \"\\t\").option(\"charset\", \"utf-8\").option(\"quote\", \"\\u0000\").save(\"dbfs:/FileStore/Taxiarchis-data-four_categories\")\n",
    "\n",
    "\n",
    "displayHTML(generateHTMLLinks(\"dbfs:/FileStore/Taxiarchis-data-four_categories\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## These are the main tables created for the final experiments - 4 categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###DOI and Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"---------------------------\" #Path has removed for  confidentiality reasons\n",
    "df_spark_doi_cat= sqlContext.read.format('csv').options(header='true', inferSchema='true').option(\"delimiter\", \"\\t\").load(path).cache()\n",
    "display(df_spark_doi_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 Categories - Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#DOI_Categories_4 ------> Contains the mappingdois with the write category\n",
    "#FullDocument_4 ------> Contains the documents as a full text  \n",
    "#perSection_4_1------> Contains all the sections/subsections  of all documents \n",
    "\n",
    "path1 = \"---------------------------\" #Path has removed for confidentiality reasons\n",
    "path2 = \"---------------------------\" #Path has removed for confidentiality reasons\n",
    "path3 = \"---------------------------\" #Path has removed for confidentiality reasons\n",
    "\n",
    "\n",
    "\n",
    "#DOI_Categories_4\n",
    "df_DOI_Categories_4= sqlContext.read.format('csv').options(header='true', inferSchema='true').option(\"delimiter\", \"\\t\").load(path1)\n",
    "\n",
    "## Write Frame out as Table\n",
    "df_DOI_Categories_4.write.mode(\"overwrite\").saveAsTable(\"taxiarchis.DOI_Categories_4\")\n",
    "\n",
    "\n",
    "# FullDocument_4\n",
    "df_FullDocument_4= sqlContext.read.format('csv').options(header='true', inferSchema='true').option(\"delimiter\", \"\\t\").load(path2)\n",
    "\n",
    "## Write Frame out as Table\n",
    "df_FullDocument_4.write.mode(\"overwrite\").saveAsTable(\"taxiarchis.FullDocument_4\")\n",
    "\n",
    "\n",
    "\n",
    "#perSection_4_1\n",
    "df_perSection_4_1 = sqlContext.read.format('csv').options(header='true', inferSchema='true').option(\"delimiter\", \"\\t\").load(path3)\n",
    "\n",
    "## Write Frame out as Table\n",
    "df_perSection_4_1.write.mode(\"overwrite\").saveAsTable(\"taxiarchis.perSection_4_1\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset of sections for the ensemble tested method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Section_4_4_Ensemble------> Contains all the sections/subsections  of all documents. Each document have been split in four parts 1) Abstract 2) Intrroduction 3) in detween 4)Conclusion \n",
    "\n",
    "path_ensembele =  \"---------------------------\" #Path has removed for confidentiality reasons\n",
    "\n",
    "#perSection_4_1\n",
    "df_perSection_4_4 = sqlContext.read.format('csv').options(header='true', inferSchema='true').option(\"delimiter\", \"\\t\").load(path_ensembele)\n",
    "\n",
    "## Write Frame out as Table\n",
    "df_perSection_4_4.write.mode(\"overwrite\").saveAsTable(\"taxiarchis.Section_4_4_Ensemble\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The mapping of the DOIs with the categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_doi =  \"---------------------------\" #Path has removed  for confidentiality reasons\n",
    "\n",
    "#perSection_4_1\n",
    "df_perSection_4_4_1 = sqlContext.read.format('csv').options(header='true', inferSchema='true').option(\"delimiter\", \"\\t\").load(path_doi)\n",
    "\n",
    "## Write Frame out as Table\n",
    "df_perSection_4_4_1.write.mode(\"overwrite\").saveAsTable(\"taxiarchis.doi_categories_4_4_features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "name": "Multiclass_Classification_PrepareDatasets",
  "notebookId": 980832
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import (RegexTokenizer, Tokenizer, HashingTF, IDF,\n",
    "                                StopWordsRemover, CountVectorizer, StopWordsRemover, StringIndexer, OneHotEncoder)\n",
    "from pyspark.ml.evaluation import (BinaryClassificationEvaluator,\n",
    "                                  MulticlassClassificationEvaluator)\n",
    "from pyspark.sql.types import (LongType ,StringType, IntegerType,\n",
    "                               FloatType, DoubleType, ArrayType)\n",
    "from pyspark.sql.functions import col, udf, avg\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pyspark.ml.clustering import LDA\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.sql.functions import countDistinct\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "from pyspark.sql import HiveContext\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FOR ENSEMBLE EXPERIMENT ONLY!!!\n",
    "df_doiCateg = spark.sql(\"SELECT * FROM taxiarchis.doi_categories_4_4_features\")\n",
    "df = spark.sql(\"SELECT * FROM taxiarchis.section_4_4_ensemble\").dropna()\n",
    "\n",
    "indexer = StringIndexer(inputCol=\"Category\", outputCol=\"label\")\n",
    "indexed = indexer.fit(df_doiCateg).transform(df_doiCateg)\n",
    "\n",
    "#transfrom to pandas\n",
    "df_cat = indexed.toPandas()\n",
    "\n",
    "# #TRAINING-VALIDATION (0.4-0.6)\n",
    "# #Split the DOIs for training and Test-----random state =42\n",
    "\n",
    "# X_train, X_validation, y_train, y_validation  = train_test_split(df_cat['DOI'],df_cat['label'], test_size=0.6, random_state=42)\n",
    "\n",
    "\n",
    "# #KEEP IT FOR VECTORIZE LATER\n",
    "# second_split_back_up = X_validation\n",
    "\n",
    "\n",
    "\n",
    "# #VALIDATION-TEST (0.66-0.34)--->(0.4,0.2) from original dataset\n",
    "# X_validation, X_test, y_validation, y_test = train_test_split(X_validation, y_validation, test_size=0.34, random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_cat['DOI'],df_cat['label'], test_size=0.30, random_state=42)\n",
    "second_split_back_up = X_train\n",
    "\n",
    "print(len(X_train))\n",
    "#print(len(X_validation))\n",
    "print(len(X_test))\n",
    "print(len(second_split_back_up))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "regexTokenizer = RegexTokenizer(inputCol=\"Section\", outputCol=\"tokens\", pattern=\"\\\\W\")\n",
    "remover = StopWordsRemover(inputCol='tokens', outputCol='filtered')\n",
    "count_vec = CountVectorizer(inputCol='filtered', outputCol='count_vec')\n",
    "idf = IDF(inputCol='count_vec', outputCol='features',minDocFreq=2)\n",
    "\n",
    "#STRINGINDEXER THE DOC_ID\n",
    "\n",
    "int_category = StringIndexer(inputCol='Category',outputCol='label')\n",
    "int_sections = StringIndexer(inputCol = 'doc_id', outputCol ='uni_sec_id')\n",
    "\n",
    "\n",
    "prep_pipeline = Pipeline(stages = [int_category, int_sections, regexTokenizer, remover, count_vec, idf])\n",
    "pre_processing = prep_pipeline.fit(df)\n",
    "pre_processed_data = pre_processing.transform(df)\n",
    "\n",
    "final_data_2 = pre_processed_data.select(['doc_id','uni_sec_id','DOI','label','features']).cache()\n",
    "# display(final_data)\n",
    "final_data_2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "regexTokenizer = RegexTokenizer(inputCol=\"Section\", outputCol=\"tokens\", pattern=\"\\\\W\")\n",
    "remover = StopWordsRemover(inputCol='tokens', outputCol='filtered')\n",
    "count_vec = CountVectorizer(inputCol='filtered', outputCol='count_vec')\n",
    "idf = IDF(inputCol='count_vec', outputCol='features',minDocFreq=2)\n",
    "\n",
    "#STRINGINDEXER THE DOC_ID\n",
    "\n",
    "int_category = StringIndexer(inputCol='Category',outputCol='label')\n",
    "int_sections = StringIndexer(inputCol = 'doc_id', outputCol ='uni_sec_id')\n",
    "\n",
    "\n",
    "prep_pipeline = Pipeline(stages = [int_category, int_sections, regexTokenizer, remover, count_vec, idf])\n",
    "pre_processing = prep_pipeline.fit(df)\n",
    "pre_processed_data = pre_processing.transform(df)\n",
    "\n",
    "final_data = pre_processed_data.select(['doc_id','uni_sec_id','DOI','label','features']).cache()\n",
    "# display(final_data)\n",
    "final_data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.clustering import LDA\n",
    "\n",
    "regexTokenizer = RegexTokenizer(inputCol='Section', outputCol=\"tokens\", pattern=\"\\\\W\")\n",
    "remover = StopWordsRemover(inputCol='tokens', outputCol='filtered')\n",
    "count_vec = CountVectorizer(inputCol='filtered', outputCol='features')\n",
    "\n",
    "int_category = StringIndexer(inputCol='Category',outputCol='label')\n",
    "int_id = StringIndexer(inputCol='doc_id',outputCol='id') #map each unique document with an id\n",
    "#PIPELINE\n",
    "\n",
    "\n",
    "prep_pipeline = Pipeline(stages = [int_category, int_id, regexTokenizer, remover, count_vec])\n",
    "\n",
    "pre_processing = prep_pipeline.fit(df)\n",
    "pre_processed_data = pre_processing.transform(df)\n",
    "\n",
    "final_data_LDA = pre_processed_data.cache()\n",
    "\n",
    "\n",
    "\n",
    "final_data_LDA = final_data_LDA.dropDuplicates(['id'])\n",
    "# final_data_LDA = final_data_LDA.select(['id','DOI','contENT','features','Section','Category','Sections','label'])\n",
    "# final_data_LDA.count()\n",
    "\n",
    "# Trains a LDA model.\n",
    "lda = LDA(k=30, maxIter=50, optimizer=\"em\")\n",
    "model = lda.fit(final_data_LDA.select('id','features'))\n",
    "\n",
    "\n",
    "#Create LDA features\n",
    "transformed = model.transform(final_data_LDA)\n",
    "final_data = transformed.select(['DOI','label','topicDistribution']).withColumnRenamed(\"topicDistribution\", \"features\").cache()\n",
    "\n",
    "\n",
    "\n",
    "transformed_2 = model.transform(final_data_LDA)\n",
    "final_data_2 = transformed_2.select(['DOI','label','topicDistribution']).withColumnRenamed(\"topicDistribution\", \"features\").cache()\n",
    "\n",
    "\n",
    "transformed_3 = model.transform(final_data_LDA)\n",
    "final_data_3 = transformed_3.select(['DOI','label','topicDistribution']).withColumnRenamed(\"topicDistribution\", \"features\").cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.clustering import LDA\n",
    "\n",
    "regexTokenizer = RegexTokenizer(inputCol='Section', outputCol=\"tokens\", pattern=\"\\\\W\")\n",
    "remover = StopWordsRemover(inputCol='tokens', outputCol='filtered')\n",
    "count_vec = CountVectorizer(inputCol='filtered', outputCol='features')\n",
    "\n",
    "int_category = StringIndexer(inputCol='Category',outputCol='label')\n",
    "int_id = StringIndexer(inputCol='doc_id',outputCol='id') #map each unique document with an id\n",
    "#PIPELINE\n",
    "\n",
    "\n",
    "prep_pipeline = Pipeline(stages = [int_category, int_id, regexTokenizer, remover, count_vec])\n",
    "\n",
    "pre_processing = prep_pipeline.fit(df)\n",
    "pre_processed_data = pre_processing.transform(df)\n",
    "\n",
    "final_data_LDA = pre_processed_data.cache()\n",
    "\n",
    "\n",
    "\n",
    "final_data_LDA = final_data_LDA.dropDuplicates(['id'])\n",
    "# final_data_LDA = final_data_LDA.select(['id','DOI','contENT','features','Section','Category','Sections','label'])\n",
    "# final_data_LDA.count()\n",
    "\n",
    "# Trains a LDA model.\n",
    "lda = LDA(k=100, maxIter=50, optimizer=\"em\")\n",
    "model = lda.fit(final_data_LDA.select('id','features'))\n",
    "\n",
    "\n",
    "#Create LDA features\n",
    "transformed = model.transform(final_data_LDA)\n",
    "final_data = transformed.select(['DOI','label','topicDistribution']).withColumnRenamed(\"topicDistribution\", \"features\").cache()\n",
    "final_data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.classification import (RandomForestClassifier, GBTClassifier,\n",
    "                                      DecisionTreeClassifier)\n",
    "from pyspark.ml.classification import LinearSVC, OneVsRest\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "#Multinomial Naive Bayes\n",
    "nb = NaiveBayes()\n",
    "\n",
    "#Decision Tree - Random Forest \n",
    "dtc = DecisionTreeClassifier(maxDepth = 12)\n",
    "# maxDepth = 15\n",
    "rfc = RandomForestClassifier(numTrees = 200, maxDepth = 20)\n",
    "\n",
    "#Linear SVM - One vs All\n",
    "lsvc = LinearSVC(maxIter=10, regParam=0.2)\n",
    "ovr = OneVsRest(classifier=lsvc  )\n",
    "\n",
    "#Logistic Regression\n",
    "lr = LogisticRegression(maxIter=15, regParam=0.0, elasticNetParam=0.0 )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPLIT TRAINING-VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train\n",
    "train = final_data.filter(final_data.DOI.isin(list(X_train)))\n",
    "\n",
    "# #validation\n",
    "# validation = final_data.filter(final_data.DOI.isin(list(X_validation)))\n",
    "\n",
    "#validation\n",
    "validation = final_data.filter(final_data.DOI.isin(list(X_test)))\n",
    "#For strong classifier Ensemble\n",
    "sec_classifir_vec  = final_data.filter(final_data.DOI.isin(list(second_split_back_up)))\n",
    "\n",
    "print(train.count())\n",
    "print(validation.count())\n",
    "print(sec_classifir_vec.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For the LDA representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train\n",
    "train_2 = final_data_2.filter(final_data_2.DOI.isin(list(X_train)))\n",
    "\n",
    "# #validation\n",
    "# validation = final_data.filter(final_data.DOI.isin(list(X_validation)))\n",
    "\n",
    "#validation\n",
    "validation_2 = final_data_2.filter(final_data_2.DOI.isin(list(X_test)))\n",
    "#For strong classifier Ensemble\n",
    "sec_classifir_vec_2  = final_data_2.filter(final_data_2.DOI.isin(list(second_split_back_up)))\n",
    "\n",
    "print(train_2.count())\n",
    "print(validation_2.count())\n",
    "print(sec_classifir_vec_2.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train\n",
    "train_3 = final_data_3.filter(final_data_3.DOI.isin(list(X_train)))\n",
    "\n",
    "# #validation\n",
    "# validation = final_data.filter(final_data.DOI.isin(list(X_validation)))\n",
    "\n",
    "#validation\n",
    "validation_3 = final_data_3.filter(final_data_3.DOI.isin(list(X_test)))\n",
    "#For strong classifier Ensemble\n",
    "sec_classifir_vec_3  = final_data_3.filter(final_data_3.DOI.isin(list(second_split_back_up)))\n",
    "\n",
    "print(train_3.count())\n",
    "print(validation_3.count())\n",
    "print(sec_classifir_vec_3.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_measures(new_df_p):\n",
    "    '''\n",
    "    Predict all the evaluation Measures:\n",
    "    Accuracy, F1-Score, Recall, Precision\n",
    "    '''\n",
    "    \n",
    "    ev_m = []\n",
    "    \n",
    "    #ACCURACY\n",
    "    acc_eval = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",metricName = 'accuracy')\n",
    "    accuracy = acc_eval.evaluate(new_df_p)\n",
    "    print(\"Accuracy = %g\" % accuracy)\n",
    "    ev_m.append(accuracy)\n",
    "    \n",
    "    #F1-SCORE\n",
    "    acc_eval_f1 = MulticlassClassificationEvaluator(metricName = 'f1')\n",
    "    f1_score = acc_eval_f1.evaluate(new_df_p)\n",
    "    print(\"f1 = %g\" % f1_score)\n",
    "    ev_m.append(f1_score)\n",
    "    \n",
    "    #RECALL\n",
    "    acc_eval_recall = MulticlassClassificationEvaluator(metricName = 'weightedRecall')\n",
    "    recall = acc_eval_recall.evaluate(new_df_p)\n",
    "    print(\"weightedRecall = %g\" % recall)\n",
    "    ev_m.append(recall)\n",
    "    \n",
    "    #PRECISION\n",
    "    acc_eval_precission = MulticlassClassificationEvaluator(metricName = \"weightedPrecision\")\n",
    "    precission = acc_eval_precission.evaluate(new_df_p)\n",
    "    print(\"weightedPrecision = %g\" % precission)\n",
    "    ev_m.append(precission)\n",
    "    \n",
    "    return ev_m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train - Evaluate - Transform for the second classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train classifier - train set\n",
    "paper_class = lr.fit(train) #\n",
    "paper_class_2 = dtc.fit(train_2)\n",
    "paper_class_3 = rfc.fit(train_3)\n",
    "#Prepare features for the second Classifier\n",
    "# df_Second = paper_class.transform(sec_classifir_vec)\n",
    "\n",
    "\n",
    "\n",
    "df_Second = paper_class.transform(final_data)\n",
    "df_Second_2 = paper_class_2.transform(final_data_2)\n",
    "df_Second_3 = paper_class_3.transform(final_data_3)\n",
    "\n",
    "\n",
    "df_Second_train = paper_class.transform(sec_classifir_vec)\n",
    "df_Second_2_train = paper_class_2.transform(sec_classifir_vec_2)\n",
    "df_Second_3_train = paper_class_3.transform(sec_classifir_vec_3)\n",
    "\n",
    "\n",
    "\n",
    "#predict labels - validation set\n",
    "# validation_results = paper_class.transform(validation)\n",
    "# evaluation_measures(validation_results)\n",
    "\n",
    "print(df_Second.count())\n",
    "print(df_Second_2.count())\n",
    "print(df_Second_3.count())\n",
    "print(df_Second_train.count())\n",
    "print(df_Second_2_train.count())\n",
    "print(df_Second_3_train.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Second.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_maximum(test_results):\n",
    "    '''\n",
    "    Finds the maximum probability and \n",
    "    prepares the dataframe for the Majority Vote.\n",
    "    '''  \n",
    "    udf_wf_var = udf(lambda x: round(np.max(np.array(x)),10), returnType=FloatType()) #Define UDF function\n",
    "    df =  test_results.withColumn('WF_Var',udf_wf_var('probability')).dropna()\n",
    "\n",
    "    return df.groupby(\"DOI\").agg(F.collect_list('prediction').alias('list_categ'),F.collect_list('WF_Var').alias('prob_categ'),F.collect_list('doc_id').alias('Sec_ids'))\n",
    "\n",
    "test_df_sect = find_maximum(validation_results)\n",
    "display(test_df_sect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Vectorized Dataframe for the Second Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pyspark.sql.types import (LongType ,StringType, IntegerType,\n",
    "                               FloatType, DoubleType, ArrayType)\n",
    "from pyspark.sql.functions import countDistinct\n",
    "\n",
    "##TEST SECOND SCENARIO\n",
    "\n",
    "\n",
    "def find_maximum_3(test_results):\n",
    "    '''\n",
    "    Finds the maximum probability and \n",
    "    prepares the dataframe for the Majority Vote.\n",
    "    '''  \n",
    "    udf_wf_var = udf(lambda x: round(np.max(np.array(x)),10), returnType=FloatType()) #Define UDF function\n",
    "    df =  test_results.withColumn('WF_Var',udf_wf_var('probability')).dropna()\n",
    "\n",
    "    return df.groupby(\"DOI\").agg(F.collect_list('prediction').alias('list_categ'),F.collect_list('WF_Var').alias('prob_categ_3'))\n",
    "\n",
    "\n",
    "def find_maximum_2(test_results):\n",
    "    '''\n",
    "    Finds the maximum probability and \n",
    "    prepares the dataframe for the Majority Vote.\n",
    "    '''  \n",
    "    udf_wf_var = udf(lambda x: round(np.max(np.array(x)),10), returnType=FloatType()) #Define UDF function\n",
    "    df =  test_results.withColumn('WF_Var',udf_wf_var('probability')).dropna()\n",
    "\n",
    "    return df.groupby(\"DOI\").agg(F.collect_list('prediction').alias('list_categ'),F.collect_list('WF_Var').alias('prob_categ_2'))\n",
    "\n",
    "\n",
    "\n",
    "def find_maximum(test_results):\n",
    "    '''\n",
    "    Finds the maximum probability and \n",
    "    prepares the dataframe for the Majority Vote.\n",
    "    '''  \n",
    "    udf_wf_var = udf(lambda x: round(np.max(np.array(x)),10), returnType=FloatType()) #Define UDF function\n",
    "    df =  test_results.withColumn('WF_Var',udf_wf_var('probability')).dropna()\n",
    "\n",
    "    return df.groupby(\"DOI\").agg(F.collect_list('prediction').alias('list_categ'),F.collect_list('WF_Var').alias('prob_categ'))\n",
    "\n",
    "\n",
    "def filter_arrays(ar):\n",
    "    '''\n",
    "    Returns only the arrays that match with \n",
    "    the array_length.\n",
    "    '''\n",
    "    array_length = 4\n",
    "    if len(ar)!=array_length:\n",
    "          return int(0)\n",
    "    else:\n",
    "          return int(1)\n",
    "    \n",
    "\n",
    "def clear_corrupt_vectors(new_set):\n",
    "    '''\n",
    "    Filter out corrupt or unmatching \n",
    "    vector lengths by using the filter_arrays\n",
    "    function. The function has a fixed length of 4\n",
    "    need to be changed if needs to be tested higher vectors.\n",
    "    '''\n",
    "    flt = udf( filter_arrays,IntegerType())\n",
    "    filt_df =new_set.withColumn('binary_filter',flt(new_set.prob_categ))\n",
    "\n",
    "    return filt_df.filter(col('binary_filter').isin([1]))\n",
    "\n",
    "def clear_corrupt_vectors_2(new_set):\n",
    "    '''\n",
    "    Filter out corrupt or unmatching \n",
    "    vector lengths by using the filter_arrays\n",
    "    function. The function has a fixed length of 4\n",
    "    need to be changed if needs to be tested higher vectors.\n",
    "    '''\n",
    "    flt = udf( filter_arrays,IntegerType())\n",
    "    filt_df =new_set.withColumn('binary_filter',flt(new_set.prob_categ_2))\n",
    "\n",
    "    return filt_df.filter(col('binary_filter').isin([1]))\n",
    "\n",
    "def clear_corrupt_vectors_3(new_set):\n",
    "    '''\n",
    "    Filter out corrupt or unmatching \n",
    "    vector lengths by using the filter_arrays\n",
    "    function. The function has a fixed length of 4\n",
    "    need to be changed if needs to be tested higher vectors.\n",
    "    '''\n",
    "    flt = udf( filter_arrays,IntegerType())\n",
    "    filt_df =new_set.withColumn('binary_filter',flt(new_set.prob_categ_3))\n",
    "\n",
    "    return filt_df.filter(col('binary_filter').isin([1]))\n",
    "\n",
    "def vectorize_array(df):\n",
    "    '''\n",
    "    Vectorize a dataframe's column with arrays.\n",
    "    Preparing the dataframe for the classifier.\n",
    "    '''\n",
    "    to_vector = udf(lambda a: Vectors.dense(a), VectorUDT())\n",
    "    \n",
    "    return df.select('DOI', to_vector(\"prob_categ\").alias(\"features_1\"))\n",
    "\n",
    "\n",
    "def vectorize_array_2(df):\n",
    "    '''\n",
    "    Vectorize a dataframe's column with arrays.\n",
    "    Preparing the dataframe for the classifier.\n",
    "    '''\n",
    "    to_vector = udf(lambda a: Vectors.dense(a), VectorUDT())\n",
    "    \n",
    "    return df.select('DOI', to_vector(\"prob_categ_2\").alias(\"features_2\"))\n",
    "  \n",
    "def vectorize_array_3(df):\n",
    "    '''\n",
    "    Vectorize a dataframe's column with arrays.\n",
    "    Preparing the dataframe for the classifier.\n",
    "    '''\n",
    "    to_vector = udf(lambda a: Vectors.dense(a), VectorUDT())\n",
    "    \n",
    "    return df.select('DOI', to_vector(\"prob_categ_3\").alias(\"features_3\"))\n",
    "  \n",
    "def prepare_for_strong_classifier(test_results):\n",
    "    '''\n",
    "    Uses all the above functions to transform\n",
    "    '''\n",
    "    \n",
    "    #Find Maximum Probability and prepare dataframe for majority vote\n",
    "    df_prep = find_maximum(test_results)\n",
    "\n",
    "    #prepare the dataset to send to the stronger classifier\n",
    "    return vectorize_array(clear_corrupt_vectors(df_prep))\n",
    "  \n",
    "#SECOND TRY \n",
    "  \n",
    "def prepare_for_strong_classifier_2(test_results):\n",
    "    '''\n",
    "    Uses all the above functions to transform\n",
    "    '''\n",
    "    \n",
    "    #Find Maximum Probability and prepare dataframe for majority vote\n",
    "    df_prep = find_maximum_2(test_results)\n",
    "\n",
    "    #prepare the dataset to send to the stronger classifier\n",
    "    return vectorize_array_2(clear_corrupt_vectors_2(df_prep))\n",
    "  \n",
    "def prepare_for_strong_classifier_3(test_results):\n",
    "    '''\n",
    "    Uses all the above functions to transform\n",
    "    '''\n",
    "    \n",
    "    #Find Maximum Probability and prepare dataframe for majority vote\n",
    "    df_prep = find_maximum_3(test_results)\n",
    "\n",
    "    #prepare the dataset to send to the stronger classifier\n",
    "    return vectorize_array_3(clear_corrupt_vectors_3(df_prep))\n",
    "    \n",
    "\n",
    "#Decision Tree\n",
    "df_train_2_1 = prepare_for_strong_classifier(df_Second)#TOD-DO CHECK IF THE COLUMSN ARE RIGHT ADN IS THE CORRECT DATAFRAME!!\n",
    "\n",
    "#Logistic Regresssion\n",
    "df_train_2_2 = prepare_for_strong_classifier_2(df_Second_2)\n",
    "\n",
    "df_train_2_3 = prepare_for_strong_classifier_3(df_Second_3)\n",
    "#FIRST MAKE THE VECTOR aSSEMBLER!!!! THEN MERGE FOR THE LABELS\n",
    "\n",
    "print(df_train_2_1.count())\n",
    "print(df_train_2_2.count())\n",
    "print(df_train_2_3.count())\n",
    "\n",
    "\n",
    "# Inner Merge with real Categories\n",
    "# df_train_2 = df_train_2.join(indexed , on=['DOI'], how='inner').dropDuplicates().dropna().cache()\n",
    "\n",
    "\n",
    "\n",
    "# display(df_train_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "assembler = VectorAssembler(inputCols = ['features_1', 'features_2','features_3'], outputCol='features')\n",
    "output = assembler.transform(df_train_test)\n",
    "display(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inner Merge with real Categories\n",
    "df_train_final = output.select(['DOI', 'features']).join(indexed , on=['DOI'], how='inner').dropDuplicates().dropna().cache()\n",
    "display(df_train_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train\n",
    "train = df_train_final.filter(df_train_final.DOI.isin(list(X_train)))\n",
    "\n",
    "# #validation\n",
    "# validation = final_data.filter(final_data.DOI.isin(list(X_validation)))\n",
    "\n",
    "#validation\n",
    "validation = df_train_final.filter(df_train_final.DOI.isin(list(X_test)))\n",
    "# #For strong classifier Ensemble\n",
    "# sec_classifir_vec  = final_data.filter(final_data.DOI.isin(list(second_split_back_up)))\n",
    "\n",
    "print(train.count())\n",
    "print(validation.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_class_2 = ovr.fit(train)\n",
    "df_Second_results = paper_class_2.transform(validation)\n",
    "evaluation_measures(df_Second_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_class_2 = rfc.fit(train)\n",
    "df_Second_results = paper_class_2.transform(validation)\n",
    "evaluation_measures(df_Second_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DONT DO IT FOR THE SECOND EXPERIMENT\n",
    "\n",
    "#validation\n",
    "validation_2 = df_train_2.filter(df_train_2.DOI.isin(list(X_validation)))\n",
    "\n",
    "#test\n",
    "test_df_f = df_train_2.filter(df_train_2.DOI.isin(list(X_test)))\n",
    "\n",
    "print(validation_2.count())\n",
    "print(test_df_f.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_2.groupBy('Category').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_f.groupBy('Category').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "paper_class_2 = rfc.fit(df_train_2)\n",
    "df_Second_results = paper_class_2.transform(validation)\n",
    "# evaluation_measures(df_Second_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Second_results.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_algo={'nb':'Multinomial Naive Bayes',\n",
    "           'lr':'Multinomial Logistic Regression',\n",
    "           'dtc':'Decision Tree Classifier',\n",
    "           'rfc':'Random Forest Classifier',\n",
    "           'ovr':'One vs Rest Linear SVM'\n",
    "}\n",
    "\n",
    "\n",
    "algorithms = [dtc, nb,lr,ovr,rfc]\n",
    "names = [\"dtc\", \"nb\", 'lr', \"ovr\",'rfc']\n",
    "for algo, n in zip(algorithms,names):\n",
    "    print(dict_algo[n])\n",
    "    paper_class_2 = algo.fit(validation_2)\n",
    "    df_Second_results = paper_class_2.transform(test_df_f)\n",
    "    evaluation_measures(df_Second_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train classifier - train set\n",
    "paper_class_2 = nb.fit(validation_2)\n",
    "\n",
    "#predict labels - test set\n",
    "df_Second_results = paper_class_2.transform(test)\n",
    "# display(df_Second_results)\n",
    "#EVALUATE\n",
    "evaluation_measures(df_Second_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Simple majority vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import HiveContext\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import functions as F\n",
    "import numpy as np\n",
    "import random \n",
    "from pyspark.sql.types import IntegerType,DoubleType\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "\n",
    "def prepare_rand_majority(df):\n",
    "  '''\n",
    "  Return a dataframe which contains\n",
    "  in each row a document and a list of\n",
    "  the predictions of the classifier prepared \n",
    "  for the majority vote.\n",
    "  '''\n",
    "  return  df.groupby(\"DOI\").agg(F.collect_list(\"prediction\").alias('list_categ'))\n",
    "\n",
    "\n",
    "def majority_vote_random(votes):\n",
    "    '''\n",
    "    Predict the majority vote by\n",
    "    returning randomly when we have more\n",
    "    than one winner class.\n",
    "    '''\n",
    "\n",
    "    vote_counts = {}\n",
    "    \n",
    "    for vote in votes:\n",
    "        if vote in vote_counts:\n",
    "            vote_counts[vote] += 1\n",
    "        else:\n",
    "            vote_counts[vote] = 1\n",
    "    winners = []\n",
    "    max_count = np.max(vote_counts.values())\n",
    "    \n",
    "    for vote, count in vote_counts.items():\n",
    "        if count == max_count:\n",
    "            winners.append(vote)\n",
    "            \n",
    "    return random.choice(winners)\n",
    "\n",
    "  \n",
    "def final_prediction_maj_random(df):\n",
    "    '''\n",
    "    Computes the final predictions based\n",
    "    on a simple majority vote.\n",
    "    '''\n",
    "    df_for_majority_vote = prepare_rand_majority(df)\n",
    "    #udf apply function\n",
    "    majority_function = udf(lambda z: majority_vote_random(z), DoubleType())\n",
    "#     final_prediction = df_for_majority_vote.withColumn('prediction', majority_function(col('list_categ')))\n",
    "    f_res = df_for_majority_vote.withColumn('prediction', majority_function(col('list_categ')))\n",
    "    return f_res.join(indexed , on=['DOI'], how='inner').dropDuplicates().dropna().cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "name": "Ensemble_2_Notebook",
  "notebookId": 1008539
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
